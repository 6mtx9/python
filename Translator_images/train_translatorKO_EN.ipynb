{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bea831a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "from datasets import load_dataset_builder\n",
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "import evaluate\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "631c094a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file spiece.model from cache at C:\\Users\\mtx/.cache\\huggingface\\hub\\models--KETI-AIR-Downstream--long-ke-t5-base-translation-aihub-ko2en\\snapshots\\ec267d5ac800975de819e962a1fb2cb0897f277a\\spiece.model\n",
      "loading file tokenizer.json from cache at C:\\Users\\mtx/.cache\\huggingface\\hub\\models--KETI-AIR-Downstream--long-ke-t5-base-translation-aihub-ko2en\\snapshots\\ec267d5ac800975de819e962a1fb2cb0897f277a\\tokenizer.json\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at C:\\Users\\mtx/.cache\\huggingface\\hub\\models--KETI-AIR-Downstream--long-ke-t5-base-translation-aihub-ko2en\\snapshots\\ec267d5ac800975de819e962a1fb2cb0897f277a\\special_tokens_map.json\n",
      "loading file tokenizer_config.json from cache at C:\\Users\\mtx/.cache\\huggingface\\hub\\models--KETI-AIR-Downstream--long-ke-t5-base-translation-aihub-ko2en\\snapshots\\ec267d5ac800975de819e962a1fb2cb0897f277a\\tokenizer_config.json\n",
      "loading configuration file config.json from cache at C:\\Users\\mtx/.cache\\huggingface\\hub\\models--KETI-AIR-Downstream--long-ke-t5-base-translation-aihub-ko2en\\snapshots\\ec267d5ac800975de819e962a1fb2cb0897f277a\\config.json\n",
      "Model config LongT5Config {\n",
      "  \"_name_or_path\": \"KETI-AIR-Downstream/long-ke-t5-base-translation-aihub-ko2en\",\n",
      "  \"architectures\": [\n",
      "    \"LongT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"encoder_attention_type\": \"transient-global\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"global_block_size\": 16,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"local_radius\": 127,\n",
      "  \"model_type\": \"longt5\",\n",
      "  \"n_positions\": 4096,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.31.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 64100\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at C:\\Users\\mtx/.cache\\huggingface\\hub\\models--KETI-AIR-Downstream--long-ke-t5-base-translation-aihub-ko2en\\snapshots\\ec267d5ac800975de819e962a1fb2cb0897f277a\\pytorch_model.bin\n",
      "Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.31.0\"\n",
      "}\n",
      "\n",
      "All model checkpoint weights were used when initializing LongT5ForConditionalGeneration.\n",
      "\n",
      "All the weights of LongT5ForConditionalGeneration were initialized from the model checkpoint at KETI-AIR-Downstream/long-ke-t5-base-translation-aihub-ko2en.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use LongT5ForConditionalGeneration for predictions without further training.\n",
      "Generation config file not found, using a generation config created from the model config.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"KETI-AIR-Downstream/long-ke-t5-base-translation-aihub-ko2en\",model_max_length=128)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"KETI-AIR-Downstream/long-ke-t5-base-translation-aihub-ko2en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5257141c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(data):\n",
    "    source_language = [value['ko'] for key, value in data.items()]\n",
    "    target_language = [value['en'] for key, value in data.items()]\n",
    "    return source_language, target_language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf77cc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "train  = load_dataset(\"Moo/korean-parallel-corpora\", split=\"train\")\n",
    "#test = load_dataset(\"Moo/korean-parallel-corpora\", split=\"test\")\n",
    "#validation = load_dataset(\"Moo/korean-parallel-corpora\", split=\"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d4031c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b75620f",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(train['ko'],return_tensors=\"pt\", max_length=128, truncation=True,padding=True)\n",
    "outputs = tokenizer(train['en'],return_tensors=\"pt\",max_length=128, truncation=True,padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8d9131",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torch.utils.data.TensorDataset(inputs.input_ids, inputs.attention_mask, outputs.input_ids, outputs.attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66690c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=1,\n",
    "    fp16=True,\n",
    "    remove_unused_columns=False,\n",
    "    logging_dir=\"./logs\",\n",
    ")\n",
    "\n",
    "def data_collator(batch):\n",
    "        return {\n",
    "            \"input_ids\": torch.stack([item[0] for item in batch]),\n",
    "            \"attention_mask\": torch.stack([item[1] for item in batch]),\n",
    "            \"labels\": torch.stack([item[2] for item in batch]),\n",
    "        }\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "\n",
    "import transformers\n",
    "transformers.logging.set_verbosity_info()\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3efabd64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a868ec49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10(tensorflow)",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
